{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Project - Chicago\n",
    "\n",
    "This project will use the map of a beautiful city, Chicago, IL, United States. I have lived here since graduating from college. I am very interested to see what the map database reveals. After unziping, the total database is a little more than 2GB.\n",
    "\n",
    "I will analyze this dataset by doing the following:\n",
    "\n",
    "* Extract a sample from the database.\n",
    "* Find the problems encountered in this dataset. \n",
    "* Clean up the data and import them to SQL.\n",
    "* Explore the data by querying in SQLite.\n",
    "* Additional ideas I have after exploring the dataset.\n",
    "\n",
    "Reference:\n",
    "\n",
    "* The summary of Chicago area can be found at [OpenStreetMap website](https://www.openstreetmap.org/relation/122604). \n",
    "* This data can be downloaded at [Mapzen Metro Extracts](https://mapzen.com/data/metro-extracts/metro/chicago_illinois/). \n",
    "* [OpenStreetMap Wiki](https://wiki.openstreetmap.org/wiki/Main_Page) shows the detail explanation of OpenStreetMap database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import lxml\n",
    "import cerberus\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, this database is quite large, more than 2GB. Directly opening it or parsing it will crash the computer. Therefore, it is a good idea to extract a sample from this dataset. \n",
    "\n",
    "I will use the extract-sample-data.py file to extract 1% of the original data. This only needs to run once. The final sample file is around 20MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3min 30s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%run extract-sample-data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the sample from the database, it is a good idea to see the big picture of this sample to see if we have had enough data within the sample. Therefore, I want to write a function to check what tags are in the sample dataset, and how many of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_file = 'sample_chicago.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tag(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        tag = elem.tag\n",
    "        if tag not in tags:\n",
    "            tags[tag] = 1\n",
    "        else:\n",
    "            tags[tag] += 1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'member': 349,\n",
       " 'nd': 103077,\n",
       " 'node': 87172,\n",
       " 'osm': 1,\n",
       " 'relation': 48,\n",
       " 'tag': 67876,\n",
       " 'way': 12337}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tag(sample_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be that we have a good amount of data within the sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem in this dataset\n",
    "\n",
    "After getting the sample data, we can look through the dataset, find the problems and clean it up.\n",
    "\n",
    "Through reading the documente and look through the sample data in a text editor, `<tag>` is used to save all the values. \n",
    "\n",
    "Here are some problems I noticed the following potential problems through reading the sample data:\n",
    "\n",
    "* The `<tag>`'s k attribute value is not consistent. Some only have lower case like \"ele\". Some have both lower case and colon, like \"gnis: id\". Others have special characters like.\n",
    "* The street name is not consistent. Some uses the whole spell, like \"street\" and \"avenue\", while others use abbreviation, like \"Ave\".\n",
    "* The phone number format is not consistent. Some have (XXX) XXX-XXXX while others have XXX-XXX-XXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k attribute issue\n",
    "\n",
    "The k-attribute has three main patterns:\n",
    "\n",
    "* The k-attribute values only contain lowercase letter, i.e. \"building\".\n",
    "* The k-attribute values contains both lowercase letter and colon, i.e. \"addr: city\".\n",
    "* The problematic pattern will contains special characters like \"&\".'\n",
    "* The rest will be \"others\".\n",
    "\n",
    "The first two patterns and \"others\" are good. They will not influence future analysis. However, the third one needs some clean-up. I will run the k_attrib_type.py file to find the patterns within my sample file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 20677, 'lower_colon': 31308, 'other': 15891, 'problemchars': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run \"k-attribute-issues.py\"\n",
    "\n",
    "k_attrib_type(sample_file, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this result, there is no problematic characters within k attributes. Therefore, we do not need to clean k attribute for future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v attribute issue\n",
    "\n",
    "The v-attribute contains the value for k-attribute. There are two v attributes that I found have some potential problems after looking through the sample file in a text editor.\n",
    "\n",
    "* Many of the street name in this file use abbreviation. For example, it uses 'Dr' instead of 'Drive'. It may causes problems in later analysis. Therefore, I need to find abbreviation and fix them.\n",
    "* The phone number in this .osm file is not consistent. After looking through a small sample of this file, I found at least four kinds of format. Some phone numbers look like \"XXX-XXX-XXXX\", some look like \"(XXX) XXX-XXXX\", some look like \"+1-XXX-XXX-XXXX\" while others look like \"(XXX)XXX-XXXX\". There might be other formats as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'14': {'U.S. 14'},\n",
       "             'Ave': {'Alabama Ave', 'New York Ave'},\n",
       "             'Ave.': {'Ogden Ave.'},\n",
       "             'B': {'South Avenue B'},\n",
       "             'Broadway': {'North Broadway'},\n",
       "             'C': {'South Avenue C'},\n",
       "             'C405': {'S Williams St #C405'},\n",
       "             'Circle': {'Woodland Park Circle'},\n",
       "             'Ct': {'Boulder Ct', 'Timber Ct', 'Vail Ct'},\n",
       "             'Dr': {'Breckenridge Dr',\n",
       "              'Greenbriar Dr',\n",
       "              'Gregory M Sears Dr',\n",
       "              'John M Boor Dr',\n",
       "              'Summit Dr'},\n",
       "             'E': {'South Avenue E'},\n",
       "             'F': {'South Avenue F'},\n",
       "             'G': {'South Avenue G'},\n",
       "             'H': {'South Avenue H'},\n",
       "             'Highway': {'Lincoln Highway', 'North Northwest Highway'},\n",
       "             'J': {'South Avenue J'},\n",
       "             'L': {'South Avenue L'},\n",
       "             'Ln': {'Leadville Ln'},\n",
       "             'M': {'South Avenue M'},\n",
       "             'N': {'900 N', 'South Avenue N'},\n",
       "             'O': {'South Avenue O'},\n",
       "             'Park': {'West Midway Park'},\n",
       "             'Path': {'Shining Moon Path'},\n",
       "             'St': {'Kathleen St', 'Tipperary St', 'Towne St'},\n",
       "             'Terrace': {'Colfax Terrace',\n",
       "              'Harvard Terrace',\n",
       "              'Hull Terrace',\n",
       "              'North Edgebrook Terrace',\n",
       "              'North Geneva Terrace'},\n",
       "             'West': {'Ginny Lane West', 'North Lincoln Park West'}})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run audit-street-types.py\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "expected = ['Street', 'Avenue', 'Boulevard', 'Drive', 'Court', 'Place',\n",
    "            'Square', 'Lane', 'Road', 'Trail', 'Parkway', 'Commons']\n",
    "\n",
    "v_attrib_types(sample_file, \"addr:street\", street_type_re, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'(312) 369-7900': {'(312) 369-7900'},\n",
       "             '(708) 749-0895': {'(708) 749-0895'},\n",
       "             '(847)434-0300': {'(847)434-0300'},\n",
       "             '(847)806-1230': {'(847)806-1230'},\n",
       "             '+1-708-715-7746': {'+1-708-715-7746'}})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_type_re = re.compile(r'(\\+1-)?\\(?\\d\\d\\d\\)?[-| ]?\\d\\d\\d[-| ]?\\d\\d\\d\\d')\n",
    "expected = re.compile(r'^\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d$')\n",
    "\n",
    "v_attrib_types(sample_file, \"phone\", phone_type_re, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the problems\n",
    "\n",
    "We have audited the Chicago osm file, and it is time to clean it.\n",
    "\n",
    "Based on the previous analysis, there is no problematic characters within 'k' attributes. I will not update this part.\n",
    "\n",
    "The street type is inconsistent. There are many abbreviations inside. I will creating a mapping to update these parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {\"St\": \"Street\",\n",
    "           \"St.\": \"Street\",\n",
    "           \"Ave\": 'Avenue',\n",
    "           'Rd.': 'Road',\n",
    "           'Dr': 'Drive',\n",
    "           'E': 'East',\n",
    "           'Highway': 'Highway'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    '''\n",
    "    This function will update the name based on the given mapping\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "    name: the unexpected street name found in the file\n",
    "    mapping: the mapping for updating the name\n",
    "\n",
    "    Return:\n",
    "    the updated name\n",
    "    '''\n",
    "    update_name = name.split(' ')[-1]\n",
    "    if update_name in mapping:\n",
    "        new_name = mapping[update_name]\n",
    "\n",
    "        name = name.replace(update_name, new_name)\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_file(filename):\n",
    "    '''\n",
    "    This function will bring audit() and update_name() functions together to\n",
    "    update the street names to make them consistenct\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    filename: the .xml or .osm file that needs to be updated\n",
    "\n",
    "    Return\n",
    "    ---\n",
    "    the updated file\n",
    "    '''\n",
    "    street_types = audit(filename)\n",
    "    for street_type, ways in street_types.items():\n",
    "        for name in ways:\n",
    "            name = update_name(name, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_file(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for item in NODE_FIELDS:\n",
    "            node_attribs[item] = element.get(item)\n",
    "        for child in element:\n",
    "            tag_dict = {}\n",
    "            colon = child.get('k').find(':')\n",
    "            if (child.tag == 'tag'):\n",
    "                tag_dict['id'] = element.get('id')\n",
    "                tag_dict['value'] = child.get('v')\n",
    "                if (colon != -1):\n",
    "                    type_value = child.get('k')[:colon]\n",
    "                    key_value = child.get('k')[colon+1:]\n",
    "                    tag_dict['type'] = type_value\n",
    "                    tag_dict['key'] = key_value\n",
    "                else:\n",
    "                    tag_dict['key'] = child.get('k')\n",
    "                    tag_dict['type'] = 'regular'\n",
    "                tags.append(tag_dict)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for item in WAY_FIELDS:\n",
    "            way_attribs[item] = element.get(item)\n",
    "            \n",
    "        n = 0\n",
    "        for child in element:\n",
    "            if child.tag == 'nd':\n",
    "                nd_dict = {}\n",
    "                nd_dict['id'] = element.get('id')\n",
    "                nd_dict['node_id'] = child.get('ref')\n",
    "                nd_dict['position'] = n\n",
    "                n += 1\n",
    "                way_nodes.append(nd_dict)\n",
    "            \n",
    "            if (child.tag == 'tag'):\n",
    "                way_tag_dict = {}\n",
    "                colon = child.get('k').find(':')\n",
    "                way_tag_dict['id'] = element.get('id')\n",
    "                way_tag_dict['value'] = child.get('v')\n",
    "                if (colon != -1):\n",
    "                    type_value = child.get('k')[:colon]\n",
    "                    key_value = child.get('k')[colon+1:]\n",
    "                    way_tag_dict['type'] = type_value\n",
    "                    way_tag_dict['key'] = key_value\n",
    "                else:\n",
    "                    way_tag_dict['key'] = child.get('k')\n",
    "                    way_tag_dict['type'] = 'regular'\n",
    "                tags.append(way_tag_dict)\n",
    "                \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSM_PATH = \"example.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
