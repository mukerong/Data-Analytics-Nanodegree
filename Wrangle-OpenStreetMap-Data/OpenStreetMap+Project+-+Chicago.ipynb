{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Project - Chicago\n",
    "\n",
    "This project will use the map of a beautiful city, Chicago, IL, United States. I have lived here since graduating from college. I am very interested to see what the map database reveals. After unziping, the total database is a little more than 2GB.\n",
    "\n",
    "I will analyze this dataset by doing the following:\n",
    "\n",
    "* Extract a sample from the database.\n",
    "* Find the problems encountered in this dataset. \n",
    "* Clean up the data and import them to SQL.\n",
    "* Explore the data by querying in SQLite.\n",
    "* Additional ideas I have after exploring the dataset.\n",
    "\n",
    "Reference:\n",
    "\n",
    "* The summary of Chicago area can be found at [OpenStreetMap website](https://www.openstreetmap.org/relation/122604). \n",
    "* This data can be downloaded at [Mapzen Metro Extracts](https://mapzen.com/data/metro-extracts/metro/chicago_illinois/). \n",
    "* [OpenStreetMap Wiki](https://wiki.openstreetmap.org/wiki/Main_Page) shows the detail explanation of OpenStreetMap database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, this database is quite large, more than 2GB. Directly opening it or parsing it will crash the computer. Therefore, it is a good idea to extract a sample from this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import lxml\n",
    "import cerberus\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the extract-sample-data.py file to extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3min 30s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%run extract-sample-data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will write a function to find element I want from the original .osm file, and write into a sample osm file.\n",
    "After reading through the wiki, I think the most important tag for this dataset are \"node\", \"way\", and \"relation\" tag. Therefore, the function will focus on getting the elements from these three tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "osm_file = 'chicago_illinois.osm'\n",
    "sample_file = 'sample_chicago.osm'\n",
    "\n",
    "tag = ['node', 'way', 'relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    '''\n",
    "    This function will read an XML file, get the element from desired tags.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    osm_file: .xml or .osm file\n",
    "        the XML or OSM file to be parsed\n",
    "\n",
    "    tags: string or list\n",
    "        the tag name that you want to get elements from.\n",
    "        default is ['node', 'way', 'relation']\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    .xml or .osm file\n",
    "    '''\n",
    "\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "\n",
    "    for event, elem in context:\n",
    "        if (event == 'end') and (elem.tag in tags):\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generate the elements, it is time to write it into another file.\n",
    "\n",
    "k is a parameter. It defines the one element to export for every k elements. The bigger the k is, the smaller the sample will be. Since the data is big, I choose to use 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1000\n",
    "    \n",
    "with open(sample_file, 'wb') as output:\n",
    "    output.write(bytes('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n', 'UTF-8'))\n",
    "    output.write(bytes('<osm>\\n  ', 'UTF-8'))\n",
    "\n",
    "    for i, element in enumerate(get_element(osm_file)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(bytes('</osm>', 'UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the sample from the database, it is a good idea to see the big picture of this sample to see if we have had enough data within the sample. Therefore, I want to write a function to check what tags are in the sample dataset, and how many of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tag(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        tag = elem.tag\n",
    "        if tag not in tags:\n",
    "            tags[tag] = 1\n",
    "        else:\n",
    "            tags[tag] += 1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'member': 69,\n",
       " 'nd': 10728,\n",
       " 'node': 8718,\n",
       " 'osm': 1,\n",
       " 'relation': 5,\n",
       " 'tag': 6761,\n",
       " 'way': 1233}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tag(sample_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be that we have a good amount of data within the sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem in this dataset\n",
    "\n",
    "After getting the sample data, we can look through the dataset, find the problems and clean it up.\n",
    "\n",
    "Through reading the documente and look through the sample data in a text editor, `<tag>` is used to save all the values. \n",
    "\n",
    "Here are some problems I noticed the following potential problems through reading the data:\n",
    "\n",
    "* The `<tag>`'s k attribute value is not consistent. Some only have lower case like \"ele\". Some have both lower case and colon, like \"gnis: id\". Others have special characters like.\n",
    "* The street name is not consistent. Some uses the whole spell, like \"street\" and \"avenue\", while others use abbreviation, like \"St\" and \"St.\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k attribute issue\n",
    "\n",
    "I will use regular expression to find the pattern that mentioned above. Later, I will define a function to count each pattern in the sample file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def key_type(filename, keys):\n",
    "    '''\n",
    "    This function will read through the k element and return its catogory\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    filename: .xml or .osm file\n",
    "        the file that is going to be analyzed\n",
    "    keys: a dictionary\n",
    "        a dictionary to show the catogory\n",
    "\n",
    "    Return\n",
    "    ---\n",
    "    the updated keys(a dictionary)\n",
    "    '''\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag == 'tag':\n",
    "            key = element.get('k')\n",
    "            if lower.search(key):\n",
    "                keys['lower'] += 1\n",
    "            elif re.findall(lower_colon, key):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif re.findall(problemchars, key):\n",
    "                keys['problemchars'] += 1\n",
    "            else:\n",
    "                keys['other'] += 1\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 2016, 'lower_colon': 3135, 'other': 1610, 'problemchars': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_type(sample_file, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street name issue\n",
    "\n",
    "Similar to k attribute, I will use regular expression to find the pattern about street type. I will build up a list showing the expected value, and printed street type not in the expected list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    '''\n",
    "    This function find the street_name that doesn't match the expected list\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    street_types: a dictionary\n",
    "        it is a dictionary that contains the unique key of street types\n",
    "    street_name: strings\n",
    "        the street name found in .xml or .osm file\n",
    "\n",
    "    Return\n",
    "    ---\n",
    "    None\n",
    "    '''\n",
    "    match = street_type_re.search(street_name)\n",
    "    if match:\n",
    "        street_type = match.group(0)\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(filename):\n",
    "    '''\n",
    "    This function will read a file and print the street types\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    filename: .xml or .osm file\n",
    "\n",
    "    Return\n",
    "    ---\n",
    "    street_types dictionary\n",
    "    '''\n",
    "    street_types = defaultdict(set)\n",
    "\n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'addr:street':\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'Ave': {'New York Ave'},\n",
       "             'Dr': {'Breckenridge Dr'},\n",
       "             'E': {'South Avenue E'},\n",
       "             'Highway': {'Lincoln Highway'}})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit(sample_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the problems\n",
    "\n",
    "We have audited the Chicago osm file, and it is time to clean it.\n",
    "\n",
    "Based on the previous analysis, there is no problematic characters within 'k' attributes. I will not update this part.\n",
    "\n",
    "The street type is inconsistent. There are many abbreviations inside. I will creating a mapping to update these parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {\"St\": \"Street\",\n",
    "           \"St.\": \"Street\",\n",
    "           \"Ave\": 'Avenue',\n",
    "           'Rd.': 'Road',\n",
    "           'Dr': 'Drive',\n",
    "           'E': 'East',\n",
    "           'Highway': 'Highway'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    '''\n",
    "    This function will update the name based on the given mapping\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "    name: the unexpected street name found in the file\n",
    "    mapping: the mapping for updating the name\n",
    "\n",
    "    Return:\n",
    "    the updated name\n",
    "    '''\n",
    "    update_name = name.split(' ')[-1]\n",
    "    if update_name in mapping:\n",
    "        new_name = mapping[update_name]\n",
    "\n",
    "        name = name.replace(update_name, new_name)\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_file(filename):\n",
    "    '''\n",
    "    This function will bring audit() and update_name() functions together to\n",
    "    update the street names to make them consistenct\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    filename: the .xml or .osm file that needs to be updated\n",
    "\n",
    "    Return\n",
    "    ---\n",
    "    the updated file\n",
    "    '''\n",
    "    street_types = audit(filename)\n",
    "    for street_type, ways in street_types.items():\n",
    "        for name in ways:\n",
    "            name = update_name(name, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_file(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for item in NODE_FIELDS:\n",
    "            node_attribs[item] = element.get(item)\n",
    "        for child in element:\n",
    "            tag_dict = {}\n",
    "            colon = child.get('k').find(':')\n",
    "            if (child.tag == 'tag'):\n",
    "                tag_dict['id'] = element.get('id')\n",
    "                tag_dict['value'] = child.get('v')\n",
    "                if (colon != -1):\n",
    "                    type_value = child.get('k')[:colon]\n",
    "                    key_value = child.get('k')[colon+1:]\n",
    "                    tag_dict['type'] = type_value\n",
    "                    tag_dict['key'] = key_value\n",
    "                else:\n",
    "                    tag_dict['key'] = child.get('k')\n",
    "                    tag_dict['type'] = 'regular'\n",
    "                tags.append(tag_dict)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for item in WAY_FIELDS:\n",
    "            way_attribs[item] = element.get(item)\n",
    "            \n",
    "        n = 0\n",
    "        for child in element:\n",
    "            if child.tag == 'nd':\n",
    "                nd_dict = {}\n",
    "                nd_dict['id'] = element.get('id')\n",
    "                nd_dict['node_id'] = child.get('ref')\n",
    "                nd_dict['position'] = n\n",
    "                n += 1\n",
    "                way_nodes.append(nd_dict)\n",
    "            \n",
    "            if (child.tag == 'tag'):\n",
    "                way_tag_dict = {}\n",
    "                colon = child.get('k').find(':')\n",
    "                way_tag_dict['id'] = element.get('id')\n",
    "                way_tag_dict['value'] = child.get('v')\n",
    "                if (colon != -1):\n",
    "                    type_value = child.get('k')[:colon]\n",
    "                    key_value = child.get('k')[colon+1:]\n",
    "                    way_tag_dict['type'] = type_value\n",
    "                    way_tag_dict['key'] = key_value\n",
    "                else:\n",
    "                    way_tag_dict['key'] = child.get('k')\n",
    "                    way_tag_dict['type'] = 'regular'\n",
    "                tags.append(way_tag_dict)\n",
    "                \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSM_PATH = \"example.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
